import requests
import json
import regex

import logging
from local_llm.llms import initialize, run_llama, run_deepseek
from ..Config import MODEL_CONFIG


def local_llm_analysis(model, tokenizer, prompt):
    # api_key = MODEL_CONFIG['llm']['model_key']
    # url = "https://cn2us02.opapi.win/v1/chat/completions"

    # payload = json.dumps({
    #     "model": "gpt-4o-mini",
    #     "messages": [
    #         {
    #             "role": "system",
    #             "content": "You are a helpful assistant."
    #         },
    #         {
    #             "role": "user",
    #             "content": prompt
    #         }
    #     ]
    # })
    # headers = {
    #     'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',
    #     'Content-Type': 'application/json',
    #     "Authorization": 'Bearer ' + api_key,
    # }

    # response = requests.request("POST", url, headers=headers, data=payload)
    # res = response.json()
    # res_content = res['choices'][0]['message']['content']
    # return res_content
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": prompt},
    ]

    response = run_llama(model, tokenizer, messages)
    return response


def extract_complete_json(response_text):
    json_pattern = r"(\{(?:[^{}]|(?1))*\})"
    matches = regex.findall(json_pattern, response_text)
    if matches:
        try:
            for match in matches:
                json_data = json.loads(match)
                return json_data
        except json.JSONDecodeError as e:
            print(f"JSON Parsing Error: {e}")
    return None
