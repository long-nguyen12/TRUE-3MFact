# Core PyTorch and Transformers
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0
transformers>=4.46.0
tokenizers>=0.20.0
accelerate>=0.26.0
sentencepiece>=0.1.99

# Quantization support (optional but recommended)
bitsandbytes>=0.41.0

# Fine-tuning support (optional)
peft>=0.7.0

# Fast attention (optional, requires CUDA)
# flash-attn>=2.7.0

# Additional utilities
einops>=0.7.0
safetensors>=0.4.0
huggingface-hub>=0.20.0

# For development
ipython>=8.12.0
jupyter>=1.0.0
